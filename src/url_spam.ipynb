{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "593f30ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aa2ch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aa2ch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\aa2ch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060759fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://breathecode.herokuapp.com/asset/internal-link?id=932&path=url_spam.csv\"\n",
    "MODEL_PATH = \"models/svm_url_spam.pkl\"\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "\n",
    "def url_tokenizer(url: str):\n",
    "    url = str(url).lower()\n",
    "    raw_tokens = re.split(r\"[^a-z0-9]+\", url)\n",
    "    tokens = []\n",
    "    for t in raw_tokens:\n",
    "        if len(t) < 2:\n",
    "            continue\n",
    "        if t in STOPWORDS:\n",
    "            continue\n",
    "        tokens.append(LEMMATIZER.lemmatize(t))\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ffd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_URL)\n",
    "df.head()\n",
    "\n",
    "url_col = \"url\" if \"url\" in df.columns else df.columns[0]\n",
    "y_col = \"is_spam\" if \"is_spam\" in df.columns else df.columns[-1]\n",
    "\n",
    "X = df[url_col].astype(str)\n",
    "y = df[y_col].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592efdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[452   9]\n",
      " [ 15 124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9679    0.9805    0.9741       461\n",
      "           1     0.9323    0.8921    0.9118       139\n",
      "\n",
      "    accuracy                         0.9600       600\n",
      "   macro avg     0.9501    0.9363    0.9430       600\n",
      "weighted avg     0.9596    0.9600    0.9597       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        tokenizer=url_tokenizer,\n",
    "        token_pattern=None,\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2\n",
    "    )),\n",
    "    (\"svm\", LinearSVC())\n",
    "])\n",
    "\n",
    "base_pipeline.fit(X_train, y_train)\n",
    "y_pred = base_pipeline.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217f41d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "{'svm__C': 3, 'svm__class_weight': None, 'svm__loss': 'squared_hinge', 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)}\n",
      "[[451  10]\n",
      " [ 13 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9720    0.9783    0.9751       461\n",
      "           1     0.9265    0.9065    0.9164       139\n",
      "\n",
      "    accuracy                         0.9617       600\n",
      "   macro avg     0.9492    0.9424    0.9457       600\n",
      "weighted avg     0.9614    0.9617    0.9615       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"tfidf__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"tfidf__min_df\": [1, 2, 5],\n",
    "    \"svm__C\": [0.1, 1, 3, 10],\n",
    "    \"svm__loss\": [\"hinge\", \"squared_hinge\"],\n",
    "    \"svm__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    base_pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"f1\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "print(grid.best_params_)\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33915524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://free-gift-cards-now.com/win => no spam\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "with open(MODEL_PATH, \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "test_url = \"http://free-gift-cards-now.com/win\"\n",
    "print(test_url, \"=>\", \"spam\" if best_model.predict([test_url])[0] == 1 else \"no spam\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
